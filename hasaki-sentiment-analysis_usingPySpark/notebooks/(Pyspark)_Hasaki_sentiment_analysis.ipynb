{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u4ox_PfQGw9"
      },
      "outputs": [],
      "source": [
        "# !apt update\n",
        "# !apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "# !wget -q http://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
        "# !tar -xvf spark-3.3.0-bin-hadoop3.tgz\n",
        "# !pip install -q findspark\n",
        "# import os\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y66yfMVQGxB"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXN_k8w-QGxB"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcRARTY-QGxB"
      },
      "outputs": [],
      "source": [
        "# %cd '/content/gdrive/My Drive/LDS9/Practice/Chapter11/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcrBrVl7QGxC"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oh9XcSTBQGxC"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder \\\n",
        "        .appName(\"Hasaki Sentiment Analysis\") \\\n",
        "        .config(\"spark.driver.memory\", \"16g\") \\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYr8odbBQGxC"
      },
      "source": [
        "### Read the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgnylhTuQGxD"
      },
      "outputs": [],
      "source": [
        "data = spark.read.csv(\"data/Danh_gia.csv\", inferSchema=True, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR230q6UQGxE",
        "outputId": "98f3d85e-9076-4703-ba2b-1c10f6c55bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------------+--------------------+--------------+-------------+------+-----------+\n",
            "| id|ma_khach_hang|  noi_dung_binh_luan|ngay_binh_luan|gio_binh_luan|so_sao|ma_san_pham|\n",
            "+---+-------------+--------------------+--------------+-------------+------+-----------+\n",
            "|  1|          443|SỬ DỤNG DỄ DÀNG, ...|    29/04/2023|        17:06|     5|  308500015|\n",
            "|  2|         1030|Sử dụng dễ dãng,r...|    30/04/2023|        15:04|     5|  308500015|\n",
            "|  3|          689|Mình rất thích ha...|    30/04/2023|        18:34|     5|  422216594|\n",
            "|  4|         2519|Sản phẩm có khả n...|    17/07/2022|        13:48|     5|  204100075|\n",
            "|  5|          402|Sữa rửa mặt tốt,s...|    15/04/2023|        23:04|     5|  422208977|\n",
            "+---+-------------+--------------------+--------------+-------------+------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlHpSlJXQGxE",
        "outputId": "a14961b0-de9f-4dc4-9f45-3e4d9edf513d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- ma_khach_hang: integer (nullable = true)\n",
            " |-- noi_dung_binh_luan: string (nullable = true)\n",
            " |-- ngay_binh_luan: string (nullable = true)\n",
            " |-- gio_binh_luan: string (nullable = true)\n",
            " |-- so_sao: string (nullable = true)\n",
            " |-- ma_san_pham: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sTJfMnDQGxF"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HESj2qsQGxF"
      },
      "outputs": [],
      "source": [
        "data = data.withColumn('sentiment', when(data.so_sao >=4, \"positive\")\n",
        "                               .when(data.so_sao <= 2, \"negative\")\n",
        "                               .otherwise(\"neutral\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMDbIAZtQGxF"
      },
      "outputs": [],
      "source": [
        "data = data.select(\"noi_dung_binh_luan\", \"so_sao\", \"sentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4_VWL9wQGxF",
        "outputId": "02482882-b4c6-4f30-c69c-ba283ee18001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----+\n",
            "|sentiment|count|\n",
            "+---------+-----+\n",
            "| positive|19512|\n",
            "|  neutral| 1002|\n",
            "| negative| 1061|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.groupBy(\"sentiment\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr-y6CtkQGxF"
      },
      "source": [
        "### Clean and Prepare the Data\n",
        "- ** Create a new length feature: **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YHWvmTfQGxF",
        "outputId": "1d905c84-d23d-4518-fe23-9073e54074ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num rows of training dataset:  21575\n"
          ]
        }
      ],
      "source": [
        "# Đếm số lượt bình luận sản phẩm\n",
        "print(\"Num rows of training dataset: \", data.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ay8kWBfQGxG",
        "outputId": "8f0fe63a-2131-4ce7-8197-ad9088e9e0b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>noi_dung_binh_luan</th>\n",
              "      <td>901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>so_sao</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0\n",
              "noi_dung_binh_luan  901\n",
              "so_sao                0\n",
              "sentiment             0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check data NULL\n",
        "data.select([count(when(col(c).isNull(), c)).alias(c)\n",
        "           for c in data.columns]).toPandas().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UeBXiIDQGxG",
        "outputId": "d5d1b5ec-7793-462a-a82e-cf16016f99bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num rows of training dataset after drop Null:  20674\n"
          ]
        }
      ],
      "source": [
        "data = data.dropna()\n",
        "print(\"Num rows of training dataset after drop Null: \", data.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpkKdtkkQGxG",
        "outputId": "2d3689d6-4f64-4cef-b613-807765298261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----+\n",
            "|sentiment|count|\n",
            "+---------+-----+\n",
            "| positive|18634|\n",
            "|  neutral|  995|\n",
            "| negative| 1045|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sau khi drop giá trị NULL\n",
        "data.groupBy(\"sentiment\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7LXqu_tQGxG",
        "outputId": "3b436d32-2abc-4e37-f66b-f2f04eb8efe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------+---------+------+\n",
            "|  noi_dung_binh_luan|so_sao|sentiment|length|\n",
            "+--------------------+------+---------+------+\n",
            "|SỬ DỤNG DỄ DÀNG, ...|     5| positive|    48|\n",
            "|Sử dụng dễ dãng,r...|     5| positive|    45|\n",
            "|Mình rất thích ha...|     5| positive|    41|\n",
            "|Sản phẩm có khả n...|     5| positive|   378|\n",
            "|Sữa rửa mặt tốt,s...|     5| positive|    44|\n",
            "|Sau 77 49 dòng sr...|     5| positive|   221|\n",
            "|Đó giờ mình sài b...|     5| positive|   177|\n",
            "|Rất ok mình xài 2...|     5| positive|    26|\n",
            "|Mik bị kich ứng, ...|     4| positive|    81|\n",
            "|nhân viên tư vấn ...|     5| positive|   156|\n",
            "+--------------------+------+---------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import length\n",
        "\n",
        "data = data.withColumn('length',length(data['noi_dung_binh_luan']))\n",
        "data.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ok5t476ZQGxG",
        "outputId": "316a7bc1-25f7-4f54-d18c-f1e143dbd3c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----------------+\n",
            "|sentiment|      avg(length)|\n",
            "+---------+-----------------+\n",
            "| positive|96.85091767736395|\n",
            "|  neutral|101.3678391959799|\n",
            "| negative|76.14449760765551|\n",
            "+---------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.groupby('sentiment').mean().show()\n",
        "# Không có sự chênh lệch quá lớn về số lượng từ của các đánh giá"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RA-Y_GAiQGxG"
      },
      "outputs": [],
      "source": [
        "data = data.drop(\"length\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mpDzs8gQGxG"
      },
      "outputs": [],
      "source": [
        "# !pip install pyspark underthesea pyvi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2jernenQGxG"
      },
      "source": [
        "### Feature Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJg3MW_7QGxG"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, RegexTokenizer\n",
        "from pyspark.ml.feature import CountVectorizer, IDF, StringIndexer\n",
        "from underthesea import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94onoD6DQGxH"
      },
      "outputs": [],
      "source": [
        "data = data.withColumn(\"lower_noi_dung_binh_luan\", lower(data[\"noi_dung_binh_luan\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFVXX4e8QGxH",
        "outputId": "490e9395-a812-42bd-ef40-15b0daa77973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------+---------+------------------------+--------------------+\n",
            "|  noi_dung_binh_luan|so_sao|sentiment|lower_noi_dung_binh_luan|          token_text|\n",
            "+--------------------+------+---------+------------------------+--------------------+\n",
            "|SỬ DỤNG DỄ DÀNG, ...|     5| positive|    sử dụng dễ dàng, ...|[sử_dụng, dễ_dàng...|\n",
            "|Sử dụng dễ dãng,r...|     5| positive|    sử dụng dễ dãng,r...|[sử_dụng, dễ, dãn...|\n",
            "|Mình rất thích ha...|     5| positive|    mình rất thích ha...|[mình, rất, thích...|\n",
            "|Sản phẩm có khả n...|     5| positive|    sản phẩm có khả n...|[sản_phẩm, có, kh...|\n",
            "|Sữa rửa mặt tốt,s...|     5| positive|    sữa rửa mặt tốt,s...|[sữa, rửa, mặt, t...|\n",
            "|Sau 77 49 dòng sr...|     5| positive|    sau 77 49 dòng sr...|[sau, 77, 49, dòn...|\n",
            "|Đó giờ mình sài b...|     5| positive|    đó giờ mình sài b...|[đó, giờ, mình, s...|\n",
            "|Rất ok mình xài 2...|     5| positive|    rất ok mình xài 2...|[rất, ok, mình, x...|\n",
            "|Mik bị kich ứng, ...|     4| positive|    mik bị kich ứng, ...|[mik, bị, kich_ứn...|\n",
            "|nhân viên tư vấn ...|     5| positive|    nhân viên tư vấn ...|[nhân_viên, tư_vấ...|\n",
            "|Mùi thơm dịu nhe ...|     5| positive|    mùi thơm dịu nhe ...|[mùi, thơm, dịu_n...|\n",
            "|Mình khum đánh gi...|     5| positive|    mình khum đánh gi...|[mình, khum, đánh...|\n",
            "|dù là hay được so...|     5| positive|    dù là hay được so...|[dù, là, hay, đượ...|\n",
            "|Miếng bông quá mỏ...|     2| negative|    miếng bông quá mỏ...|[miếng, bông, quá...|\n",
            "|Xài tốt, tẩy tran...|     5| positive|    xài tốt, tẩy tran...|[xài, tốt, ,, tẩy...|\n",
            "|Hơi bết và trắng quá|     4| positive|    hơi bết và trắng quá|[hơi, bết, và, tr...|\n",
            "|        sản phẩm tốt|     5| positive|            sản phẩm tốt|     [sản_phẩm, tốt]|\n",
            "|Mua chai thứ 4 5 ...|     5| positive|    mua chai thứ 4 5 ...|[mua, chai, thứ, ...|\n",
            "|rít mặt nên đắp x...|     4| positive|    rít mặt nên đắp x...|[rít, mặt, nên, đ...|\n",
            "|         quá ok luôn|     5| positive|             quá ok luôn|     [quá, ok, luôn]|\n",
            "+--------------------+------+---------+------------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tokenization Vietnamese text with underthesea\n",
        "def tokenize_vietnamese(text):\n",
        "    return word_tokenize(text, format=\"text\").split()\n",
        "\n",
        "tokenizer_udf = udf(tokenize_vietnamese, ArrayType(StringType()))\n",
        "\n",
        "data = data.withColumn(\"token_text\", tokenizer_udf(col(\"lower_noi_dung_binh_luan\")))\n",
        "data.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rNb94mlQGxH"
      },
      "outputs": [],
      "source": [
        "# Vietnamese stopwords\n",
        "sc = spark.sparkContext\n",
        "\n",
        "stopwords_path = \"files/vietnamese-stopwords.txt\"\n",
        "stopwords_rdd = sc.textFile(stopwords_path)\n",
        "\n",
        "# Chuyển đổi sang list\n",
        "vn_stopwords_rdd = stopwords_rdd.map(lambda word: word.strip()).filter(lambda word: word)\n",
        "vietnamese_stopwords = stopwords_rdd.collect()\n",
        "# print(vietnamese_stopwords)\n",
        "\n",
        "vietnamese_stopwords_remover = StopWordsRemover(inputCol=\"token_text\", outputCol=\"stop_tokens\")\n",
        "vietnamese_stopwords_remover.setStopWords(vietnamese_stopwords) #1\n",
        "\n",
        "count_vec = CountVectorizer(inputCol='stop_tokens',outputCol='c_vec')  #2\n",
        "\n",
        "idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")  #3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tqukSNOQGxH"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "clean_up = VectorAssembler(inputCols=['tf_idf'],outputCol='features') #4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvkierXlQGxH"
      },
      "outputs": [],
      "source": [
        "class_to_num = StringIndexer(inputCol='sentiment',outputCol='label') #5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXZvRTvZQGxH"
      },
      "source": [
        "### Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzIlCQ-cQGxH"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5x-X7FEQGxH"
      },
      "outputs": [],
      "source": [
        "data_prep_pipe = Pipeline(stages=[vietnamese_stopwords_remover,\n",
        "                                  count_vec, idf, clean_up, class_to_num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz9AGOJIQGxH"
      },
      "outputs": [],
      "source": [
        "cleaner = data_prep_pipe.fit(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YpKIWM1QGxH"
      },
      "outputs": [],
      "source": [
        "clean_data = cleaner.transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky7qlRFsQGxH",
        "outputId": "f05d5bc7-dc31-4d31-85a2-02cca4e383df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------+---------+------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|  noi_dung_binh_luan|so_sao|sentiment|lower_noi_dung_binh_luan|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|label|\n",
            "+--------------------+------+---------+------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|SỬ DỤNG DỄ DÀNG, ...|     5| positive|    sử dụng dễ dàng, ...|[sử_dụng, dễ_dàng...|[dễ_dàng, ,, thoả...|(7227,[0,1,22,27,...|(7227,[0,1,22,27,...|(7227,[0,1,22,27,...|  0.0|\n",
            "|Sử dụng dễ dãng,r...|     5| positive|    sử dụng dễ dãng,r...|[sử_dụng, dễ, dãn...|[dãng, ,, thoải_m...|(7227,[0,22,28,30...|(7227,[0,22,28,30...|(7227,[0,22,28,30...|  0.0|\n",
            "|Mình rất thích ha...|     5| positive|    mình rất thích ha...|[mình, rất, thích...|[thích, va_sp, tẩ...|(7227,[14,18,2067...|(7227,[14,18,2067...|(7227,[14,18,2067...|  0.0|\n",
            "|Sản phẩm có khả n...|     5| positive|    sản phẩm có khả n...|[sản_phẩm, có, kh...|[khả_năng, sạch, ...|(7227,[0,1,2,4,11...|(7227,[0,1,2,4,11...|(7227,[0,1,2,4,11...|  0.0|\n",
            "|Sữa rửa mặt tốt,s...|     5| positive|    sữa rửa mặt tốt,s...|[sữa, rửa, mặt, t...|[sữa, rửa, mặt, t...|(7227,[0,2,4,5,10...|(7227,[0,2,4,5,10...|(7227,[0,2,4,5,10...|  0.0|\n",
            "|Sau 77 49 dòng sr...|     5| positive|    sau 77 49 dòng sr...|[sau, 77, 49, dòn...|[77, 49, srm, ,, ...|(7227,[0,1,5,15,1...|(7227,[0,1,5,15,1...|(7227,[0,1,5,15,1...|  0.0|\n",
            "|Đó giờ mình sài b...|     5| positive|    đó giờ mình sài b...|[đó, giờ, mình, s...|[sài, bha, obagi,...|(7227,[0,1,34,40,...|(7227,[0,1,34,40,...|(7227,[0,1,34,40,...|  0.0|\n",
            "|Rất ok mình xài 2...|     5| positive|    rất ok mình xài 2...|[rất, ok, mình, x...|  [ok, xài, 2, chai]|(7227,[6,15,16,31...|(7227,[6,15,16,31...|(7227,[6,15,16,31...|  0.0|\n",
            "|Mik bị kich ứng, ...|     4| positive|    mik bị kich ứng, ...|[mik, bị, kich_ứn...|[mik, kich_ứng, ,...|(7227,[0,3,37,68,...|(7227,[0,3,37,68,...|(7227,[0,3,37,68,...|  0.0|\n",
            "|nhân viên tư vấn ...|     5| positive|    nhân viên tư vấn ...|[nhân_viên, tư_vấ...|[tư_vấn, train, d...|(7227,[1,2,5,13,3...|(7227,[1,2,5,13,3...|(7227,[1,2,5,13,3...|  0.0|\n",
            "|Mùi thơm dịu nhe ...|     5| positive|    mùi thơm dịu nhe ...|[mùi, thơm, dịu_n...|[mùi, thơm, dịu_n...|(7227,[0,9,30,50,...|(7227,[0,9,30,50,...|(7227,[0,9,30,50,...|  0.0|\n",
            "|Mình khum đánh gi...|     5| positive|    mình khum đánh gi...|[mình, khum, đánh...|[khum, vụ, nâng, ...|(7227,[0,1,2,3,10...|(7227,[0,1,2,3,10...|(7227,[0,1,2,3,10...|  0.0|\n",
            "|dù là hay được so...|     5| positive|    dù là hay được so...|[dù, là, hay, đượ...|[so_sánh, nhma, ẩ...|(7227,[0,1,2,3,4,...|(7227,[0,1,2,3,4,...|(7227,[0,1,2,3,4,...|  0.0|\n",
            "|Miếng bông quá mỏ...|     2| negative|    miếng bông quá mỏ...|[miếng, bông, quá...|[miếng, mỏng, ., ...|(7227,[0,1,4,5,10...|(7227,[0,1,4,5,10...|(7227,[0,1,4,5,10...|  1.0|\n",
            "|Xài tốt, tẩy tran...|     5| positive|    xài tốt, tẩy tran...|[xài, tốt, ,, tẩy...|[xài, tốt, ,, tẩy...|(7227,[0,1,2,3,4,...|(7227,[0,1,2,3,4,...|(7227,[0,1,2,3,4,...|  0.0|\n",
            "|Hơi bết và trắng quá|     4| positive|    hơi bết và trắng quá|[hơi, bết, và, tr...|   [hơi, bết, trắng]|(7227,[26,69,114]...|(7227,[26,69,114]...|(7227,[26,69,114]...|  0.0|\n",
            "|        sản phẩm tốt|     5| positive|            sản phẩm tốt|     [sản_phẩm, tốt]|               [tốt]|    (7227,[4],[1.0])|(7227,[4],[1.6957...|(7227,[4],[1.6957...|  0.0|\n",
            "|Mua chai thứ 4 5 ...|     5| positive|    mua chai thứ 4 5 ...|[mua, chai, thứ, ...|[mua, chai, 4, 5,...|(7227,[0,5,6,15,1...|(7227,[0,5,6,15,1...|(7227,[0,5,6,15,1...|  0.0|\n",
            "|rít mặt nên đắp x...|     4| positive|    rít mặt nên đắp x...|[rít, mặt, nên, đ...|[rít, mặt, đắp, x...|(7227,[0,1,4,8,10...|(7227,[0,1,4,8,10...|(7227,[0,1,4,8,10...|  0.0|\n",
            "|         quá ok luôn|     5| positive|             quá ok luôn|     [quá, ok, luôn]|                [ok]|   (7227,[15],[1.0])|(7227,[15],[2.395...|(7227,[15],[2.395...|  0.0|\n",
            "+--------------------+------+---------+------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clean_data.show(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOFpxZ-OQGxI",
        "outputId": "c57e6fb5-0754-42cb-a508-9c05404d15b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|18634|\n",
            "|  1.0| 1045|\n",
            "|  2.0|  995|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 0:positive, 1:negative, 2:neutral\n",
        "clean_data.groupBy(\"label\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji3EBLCCQGxI"
      },
      "outputs": [],
      "source": [
        "clean_data = clean_data.select(['label','features'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqDF9u_hQGxI"
      },
      "outputs": [],
      "source": [
        "(training,testing) = clean_data.randomSplit([0.7,0.3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLY2XjR2QGxO",
        "outputId": "8ea0bd0d-8ef5-4744-eb8c-229aced9e898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|13056|\n",
            "|  1.0|  726|\n",
            "|  2.0|  719|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training.groupBy(\"label\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es6-5uqtQGxO",
        "outputId": "28ad49d8-6cdb-4907-c818-4bb1704c0c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0| 5578|\n",
            "|  1.0|  319|\n",
            "|  2.0|  276|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "testing.groupBy(\"label\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5id4WYVFQGxO"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_vG4ss4QGxO"
      },
      "source": [
        "###\n",
        "- Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU5_kWoGQGxO"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0N8xla1QGxO"
      },
      "outputs": [],
      "source": [
        "lg = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPthi46yQGxO",
        "outputId": "d303577f-9433-4424-e36d-a9dba323d4dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 49.50 seconds\n"
          ]
        }
      ],
      "source": [
        "# Measure training time\n",
        "start_time = time.time()\n",
        "predictor_lg = lg.fit(training)\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate training time\n",
        "training_time_log = end_time - start_time\n",
        "\n",
        "# Print training time\n",
        "print(f\"Training time: {training_time_log:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTQZa8s6QGxO"
      },
      "outputs": [],
      "source": [
        "test_results_lg = predictor_lg.transform(testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlBOdflTQGxP",
        "outputId": "e8ca9b9e-aa49-455a-ec97-c3fb15696452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|       0.0| 5917|\n",
            "|       1.0|  143|\n",
            "|       2.0|  113|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results_lg.groupBy('prediction').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOYRyM58QGxP",
        "outputId": "30d4e8d0-5e61-467b-9291-400f244cfa85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  2.0|       0.0|  167|\n",
            "|  1.0|       1.0|  140|\n",
            "|  1.0|       0.0|  174|\n",
            "|  2.0|       2.0|  106|\n",
            "|  2.0|       1.0|    3|\n",
            "|  1.0|       2.0|    5|\n",
            "|  0.0|       0.0| 5576|\n",
            "|  0.0|       2.0|    2|\n",
            "+-----+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a confusion matrix\n",
        "test_results_lg.groupBy('label', 'prediction').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6ACR3OSQGxP",
        "outputId": "fa68bbaa-9e14-475b-ae58-3efaf493966b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting Logistic Regression: 0.9323355753318717\n"
          ]
        }
      ],
      "source": [
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc_lg = acc_eval.evaluate(test_results_lg)\n",
        "print(\"Accuracy of model at predicting Logistic Regression: {}\".format(acc_lg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yrcqt5_XQGxP",
        "outputId": "8c808383-0238-48ee-b11f-c412ddf9bb9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before resampling data\n",
            "LR predicting Accuracy: 0.94\n",
            "LR predicting Precision: 0.94\n",
            "LR predicting Recall: 0.94\n",
            "LR predicting F1 Score: 0.93\n"
          ]
        }
      ],
      "source": [
        "print(\"Before resampling data\")\n",
        "# Multiclass evaluator for precision, recall, F1-score, and accuracy\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "accuracy = multi_evaluator.evaluate(test_results_lg, {multi_evaluator.metricName: \"accuracy\"})\n",
        "precision = multi_evaluator.evaluate(test_results_lg, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "recall = multi_evaluator.evaluate(test_results_lg, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "f1_score = multi_evaluator.evaluate(test_results_lg, {multi_evaluator.metricName: \"f1\"})\n",
        "\n",
        "# Display metrics\n",
        "print(f\"LR predicting Accuracy: {accuracy:.2f}\")\n",
        "print(f\"LR predicting Precision: {precision:.2f}\")\n",
        "print(f\"LR predicting Recall: {recall:.2f}\")\n",
        "print(f\"LR predicting F1 Score: {f1_score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FbcUsCvQGxP"
      },
      "source": [
        "###\n",
        "- Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MKR9EvvQGxP"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "nb = NaiveBayes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e4DwT9lQGxP",
        "outputId": "fb120e4b-2bc4-400d-ea1a-43c2bef17722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 24.81 seconds\n"
          ]
        }
      ],
      "source": [
        "# Measure training time\n",
        "start_time = time.time()\n",
        "predictor_nb = nb.fit(training)\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate training time\n",
        "training_time_nb = end_time - start_time\n",
        "\n",
        "# Print training time\n",
        "print(f\"Training time: {training_time_nb:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT6JtmiAQGxP"
      },
      "outputs": [],
      "source": [
        "test_results_nb = predictor_nb.transform(testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwvRn2YpQGxP",
        "outputId": "ba34fbb6-7dae-4cfb-b1c2-515fe006f1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|       0.0| 5121|\n",
            "|       1.0|  571|\n",
            "|       2.0|  481|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results_nb.groupBy('prediction').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzNaYjaWQGxP",
        "outputId": "a70f554a-6602-4dc7-bbf1-f7d479828e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  2.0|       0.0|   58|\n",
            "|  1.0|       1.0|  268|\n",
            "|  0.0|       1.0|  260|\n",
            "|  1.0|       0.0|   21|\n",
            "|  2.0|       2.0|  175|\n",
            "|  2.0|       1.0|   43|\n",
            "|  1.0|       2.0|   30|\n",
            "|  0.0|       0.0| 5042|\n",
            "|  0.0|       2.0|  276|\n",
            "+-----+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results_nb.groupBy('label', 'prediction').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HPK_6W8QGxP",
        "outputId": "a3c63f86-2b5b-43a4-ca8a-b87648633f20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting: 0.9034652839799525\n"
          ]
        }
      ],
      "source": [
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc_nb = acc_eval.evaluate(test_results_nb)\n",
        "print(\"Accuracy of model at predicting: {}\".format(acc_nb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9-tqwltQGxQ",
        "outputId": "b7acb650-c302-4ae6-bb35-bba14019367e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before resampling data\n",
            "NB predicting Accuracy: 0.89\n",
            "NB predicting Precision: 0.93\n",
            "NB predicting Recall: 0.89\n",
            "NB predicting F1 Score: 0.90\n"
          ]
        }
      ],
      "source": [
        "print(\"Before resampling data\")\n",
        "# Multiclass evaluator for precision, recall, F1-score, and accuracy\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "accuracy = multi_evaluator.evaluate(test_results_nb, {multi_evaluator.metricName: \"accuracy\"})\n",
        "precision = multi_evaluator.evaluate(test_results_nb, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "recall = multi_evaluator.evaluate(test_results_nb, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "f1_score = multi_evaluator.evaluate(test_results_nb, {multi_evaluator.metricName: \"f1\"})\n",
        "\n",
        "# Display metrics\n",
        "print(f\"NB predicting Accuracy: {accuracy:.2f}\")\n",
        "print(f\"NB predicting Precision: {precision:.2f}\")\n",
        "print(f\"NB predicting Recall: {recall:.2f}\")\n",
        "print(f\"NB predicting F1 Score: {f1_score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiEi1GPqQGxQ"
      },
      "source": [
        "###\n",
        "- RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwEuXUwcQGxQ"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GphvulIJQGxQ"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
        "                            featuresCol=\"features\", \\\n",
        "                            numTrees = 50, \\\n",
        "                            maxDepth = 5, \\\n",
        "                            maxBins = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcT5vNZvQGxQ",
        "outputId": "a26acda2-e665-45be-edb2-4dae96ff7a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 100.09 seconds\n"
          ]
        }
      ],
      "source": [
        "# Measure training time\n",
        "start_time = time.time()\n",
        "predictor_rf = rf.fit(training)\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate training time\n",
        "training_time_rf = end_time - start_time\n",
        "\n",
        "# Print training time\n",
        "print(f\"Training time: {training_time_rf:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn-PnaCfQGxQ"
      },
      "outputs": [],
      "source": [
        "test_results_rf = predictor_rf.transform(testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3c-yZYEQGxQ",
        "outputId": "d6d8d4b9-1989-4419-ce38-5682a23ae64a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|       0.0| 6173|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results_rf.groupBy('prediction').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XluLub9VQGxQ",
        "outputId": "ac5eaa75-5ca8-4f71-a82c-a59b3b3755d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  2.0|       0.0|  276|\n",
            "|  1.0|       0.0|  319|\n",
            "|  0.0|       0.0| 5578|\n",
            "+-----+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a confusion matrix\n",
        "test_results_rf.groupBy('label', 'prediction').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3DmDehHQGxQ",
        "outputId": "ddd954d5-a6d8-4b25-d9eb-2121b9fa997e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting: 0.8578590007463993\n"
          ]
        }
      ],
      "source": [
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc_rf = acc_eval.evaluate(test_results_rf)\n",
        "print(\"Accuracy of model at predicting: {}\".format(acc_rf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjhvAwP8QGxQ",
        "outputId": "9d108a0c-e6c8-4f49-8267-99833853c5a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before resampling data\n",
            "Random Forest predicting Accuracy: 0.90\n",
            "Random Forest predicting Precision: 0.82\n",
            "Random Forest predicting Recall: 0.90\n",
            "Random Forest predicting F1 Score: 0.86\n"
          ]
        }
      ],
      "source": [
        "print(\"Before resampling data\")\n",
        "# Multiclass evaluator for precision, recall, F1-score, and accuracy\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "accuracy = multi_evaluator.evaluate(test_results_rf, {multi_evaluator.metricName: \"accuracy\"})\n",
        "precision = multi_evaluator.evaluate(test_results_rf, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "recall = multi_evaluator.evaluate(test_results_rf, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "f1_score = multi_evaluator.evaluate(test_results_rf, {multi_evaluator.metricName: \"f1\"})\n",
        "\n",
        "# Display metrics\n",
        "print(f\"Random Forest predicting Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Random Forest predicting Precision: {precision:.2f}\")\n",
        "print(f\"Random Forest predicting Recall: {recall:.2f}\")\n",
        "print(f\"Random Forest predicting F1 Score: {f1_score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcHJB0-wQGxR"
      },
      "source": [
        "## Need to resample data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdLtpAVlQGxR",
        "outputId": "ae18d292-a6da-4825-b7c4-e8cefbf536f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ratio like/neutral: 17\n",
            "ratio like/not_like: 18\n"
          ]
        }
      ],
      "source": [
        "positive_df = training.filter(col(\"label\") == 0)\n",
        "negative_df = training.filter(col(\"label\") == 1)\n",
        "neutral_df = training.filter(col(\"label\") == 2)\n",
        "ratio_1 = int(positive_df.count()/negative_df.count())\n",
        "ratio_2 = int(positive_df.count()/neutral_df.count())\n",
        "print(\"ratio like/neutral: {}\".format(ratio_1))\n",
        "print(\"ratio like/not_like: {}\".format(ratio_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQWQRYyXQGxR"
      },
      "outputs": [],
      "source": [
        "# ratio1 = (ratio_1 -1)/2\n",
        "# ratio2 = ratio_2/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpBaMgA8QGxR",
        "outputId": "dc15e67c-8486-4248-cad9-e4e81fa971de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------------+\n",
            "|label|    features|\n",
            "+-----+------------+\n",
            "|  0.0|(7227,[],[])|\n",
            "|  0.0|(7227,[],[])|\n",
            "|  0.0|(7227,[],[])|\n",
            "|  0.0|(7227,[],[])|\n",
            "|  0.0|(7227,[],[])|\n",
            "+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# resample negative\n",
        "a1 = range(ratio_1)\n",
        "# duplicate the minority rows\n",
        "oversampled_negative_df = negative_df.withColumn(\"dummy\",\n",
        "                                                explode(array([lit(x) for x in a1])))\\\n",
        "                                                .drop('dummy')\n",
        "# combine both oversampled minority rows and previous majority rows\n",
        "combined_df = positive_df.unionAll(oversampled_negative_df)\n",
        "combined_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILYvgyjKQGxR",
        "outputId": "243aa94d-3bd7-4567-a555-26067108ebdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|13056|\n",
            "|  1.0|12342|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "combined_df.groupBy(\"label\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuyI89UeQGxR",
        "outputId": "59919f63-66b5-4d1a-e4c8-c7066037916a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------------+\n",
            "|label|    features|\n",
            "+-----+------------+\n",
            "|  0.0|(7227,[],[])|\n",
            "|  0.0|(7227,[],[])|\n",
            "|  0.0|(7227,[],[])|\n",
            "|  0.0|(7227,[],[])|\n",
            "|  0.0|(7227,[],[])|\n",
            "+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# resample neutral\n",
        "a2 = range(ratio_2)\n",
        "# duplicate the minority rows\n",
        "oversampled_neutral_df = neutral_df.withColumn(\"dummy\",\n",
        "                                                explode(array([lit(x) for x in a2])))\\\n",
        "                                                .drop('dummy')\n",
        "# combine both oversampled minority rows and previous majority rows\n",
        "combined_df = combined_df.unionAll(oversampled_neutral_df)\n",
        "combined_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlSdRjCqQGxR",
        "outputId": "1e23f247-b74d-4691-b316-416c6d6d7f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|13056|\n",
            "|  1.0|12342|\n",
            "|  2.0|12942|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "combined_df.groupBy(\"label\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5fTwHqrQGxR"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RulgznjHQGxR"
      },
      "outputs": [],
      "source": [
        "predictor_lg1 = lg.fit(combined_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm7xu67TQGxR"
      },
      "outputs": [],
      "source": [
        "test_results_lg1 = predictor_lg1.transform(testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-arY0ir_QGxR",
        "outputId": "c863ec8e-c0a8-4dbc-cb5e-106901e00768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0| 5578|\n",
            "|  1.0|  319|\n",
            "|  2.0|  276|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results_lg1.groupBy('label').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkISXJ-XQGxR",
        "outputId": "8b4fe71a-1fdd-4c8d-86b3-a1a1efe85ead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  2.0|       0.0|   50|\n",
            "|  1.0|       1.0|  278|\n",
            "|  0.0|       1.0|  143|\n",
            "|  1.0|       0.0|   24|\n",
            "|  2.0|       2.0|  206|\n",
            "|  2.0|       1.0|   20|\n",
            "|  1.0|       2.0|   17|\n",
            "|  0.0|       0.0| 5238|\n",
            "|  0.0|       2.0|  197|\n",
            "+-----+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results_lg1.groupBy('label', 'prediction').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijCGqcMlQGxR",
        "outputId": "6448fc4d-a448-438d-f80a-fd24c70ecd84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting: 0.9335326091378984\n"
          ]
        }
      ],
      "source": [
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc_lg1 = acc_eval.evaluate(test_results_lg1)\n",
        "print(\"Accuracy of model at predicting: {}\".format(acc_lg1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-RMfPhSQGxS",
        "outputId": "70327945-b740-477d-e045-f04d1e4a2fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After resampling data\n",
            "Logistic Regression predicting Accuracy: 0.93\n",
            "Logistic Regression predicting Precision: 0.95\n",
            "Logistic Regression predicting Recall: 0.93\n",
            "Logistic Regression predicting F1 Score: 0.93\n"
          ]
        }
      ],
      "source": [
        "print(\"After resampling data\")\n",
        "# Multiclass evaluator for precision, recall, F1-score, and accuracy\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "accuracy = multi_evaluator.evaluate(test_results_lg1, {multi_evaluator.metricName: \"accuracy\"})\n",
        "precision = multi_evaluator.evaluate(test_results_lg1, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "recall = multi_evaluator.evaluate(test_results_lg1, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "f1_score = multi_evaluator.evaluate(test_results_lg1, {multi_evaluator.metricName: \"f1\"})\n",
        "\n",
        "# Display metrics\n",
        "print(f\"Logistic Regression predicting Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Logistic Regression predicting Precision: {precision:.2f}\")\n",
        "print(f\"Logistic Regression predicting Recall: {recall:.2f}\")\n",
        "print(f\"Logistic Regression predicting F1 Score: {f1_score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tCiCf9KQGxS"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlFcCYFuQGxS"
      },
      "outputs": [],
      "source": [
        "predictor_rf1 = rf.fit(combined_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDbONf-4QGxS"
      },
      "outputs": [],
      "source": [
        "test_result_rf1 = predictor_rf1.transform(testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjaV5acIQGxS",
        "outputId": "53db2db3-ad51-4f7c-869d-220b2b0a3d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0| 5578|\n",
            "|  1.0|  319|\n",
            "|  2.0|  276|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_result_rf1.groupBy('label').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cagjd5RtQGxS",
        "outputId": "4709fd9b-03f6-4666-96ec-30703281cb21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  2.0|       0.0|  109|\n",
            "|  1.0|       1.0|  193|\n",
            "|  0.0|       1.0|  225|\n",
            "|  1.0|       0.0|   87|\n",
            "|  2.0|       2.0|  133|\n",
            "|  2.0|       1.0|   34|\n",
            "|  1.0|       2.0|   39|\n",
            "|  0.0|       0.0| 4896|\n",
            "|  0.0|       2.0|  457|\n",
            "+-----+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_result_rf1.groupBy('label', 'prediction').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbbkf6rwQGxS",
        "outputId": "629a9ec1-b09f-4a7e-db71-c39fb6e76d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting: 0.8682705066055129\n"
          ]
        }
      ],
      "source": [
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc_rf1 = acc_eval.evaluate(test_result_rf1)\n",
        "print(\"Accuracy of model at predicting: {}\".format(acc_rf1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv01lzJ5QGxS",
        "outputId": "1e916d22-c0a7-4cc3-d44c-dac0eb2ae8d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After resampling data\n",
            "Random Forest predicting Accuracy: 0.85\n",
            "Random Forest predicting Precision: 0.90\n",
            "Random Forest predicting Recall: 0.85\n",
            "Random Forest predicting F1 Score: 0.87\n"
          ]
        }
      ],
      "source": [
        "print(\"After resampling data\")\n",
        "# Multiclass evaluator for precision, recall, F1-score, and accuracy\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "accuracy = multi_evaluator.evaluate(test_result_rf1, {multi_evaluator.metricName: \"accuracy\"})\n",
        "precision = multi_evaluator.evaluate(test_result_rf1, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "recall = multi_evaluator.evaluate(test_result_rf1, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "f1_score = multi_evaluator.evaluate(test_result_rf1, {multi_evaluator.metricName: \"f1\"})\n",
        "\n",
        "# Display metrics\n",
        "print(f\"Random Forest predicting Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Random Forest predicting Precision: {precision:.2f}\")\n",
        "print(f\"Random Forest predicting Recall: {recall:.2f}\")\n",
        "print(f\"Random Forest predicting F1 Score: {f1_score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjv9GGmAQGxS"
      },
      "source": [
        "### Naive Bayer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct5WPeeeQGxS"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "\n",
        "nb = NaiveBayes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOEDvHcvQGxS"
      },
      "outputs": [],
      "source": [
        "predictor_nb1 = nb.fit(combined_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3FBtDq_QGxS"
      },
      "outputs": [],
      "source": [
        "test_results_nb1 = predictor_nb1.transform(testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0vId1x2QGxT",
        "outputId": "2fccb04c-415d-43f2-8ba8-57cb688fce39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0| 5578|\n",
            "|  1.0|  319|\n",
            "|  2.0|  276|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results_nb1.groupBy('label').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvhJETgnQGxT",
        "outputId": "aa0c1181-5c43-4aaf-e2fb-e93fcc030efb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  2.0|       0.0|   50|\n",
            "|  1.0|       1.0|  268|\n",
            "|  0.0|       1.0|  231|\n",
            "|  1.0|       0.0|   27|\n",
            "|  2.0|       2.0|  186|\n",
            "|  2.0|       1.0|   40|\n",
            "|  1.0|       2.0|   24|\n",
            "|  0.0|       0.0| 5113|\n",
            "|  0.0|       2.0|  234|\n",
            "+-----+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_results_nb1.groupBy('label', 'prediction').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNRFlvTBQGxT",
        "outputId": "18e342e5-3d7f-4f1b-aa99-087d58ff63b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting: 0.9135132338313691\n"
          ]
        }
      ],
      "source": [
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc_nb1 = acc_eval.evaluate(test_results_nb1)\n",
        "print(\"Accuracy of model at predicting: {}\".format(acc_nb1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEqsuRSlQGxT",
        "outputId": "d268a22a-829d-43b6-b4b0-81c902d4affc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After resampling data\n",
            "Naive Bayes predicting Accuracy: 0.90\n",
            "Naive Bayes predicting Precision: 0.93\n",
            "Naive Bayes predicting Recall: 0.90\n",
            "Naive Bayes predicting F1 Score: 0.91\n"
          ]
        }
      ],
      "source": [
        "print(\"After resampling data\")\n",
        "# Multiclass evaluator for precision, recall, F1-score, and accuracy\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "accuracy = multi_evaluator.evaluate(test_results_nb1, {multi_evaluator.metricName: \"accuracy\"})\n",
        "precision = multi_evaluator.evaluate(test_results_nb1, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "recall = multi_evaluator.evaluate(test_results_nb1, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "f1_score = multi_evaluator.evaluate(test_results_nb1, {multi_evaluator.metricName: \"f1\"})\n",
        "\n",
        "# Display metrics\n",
        "print(f\"Naive Bayes predicting Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Naive Bayes predicting Precision: {precision:.2f}\")\n",
        "print(f\"Naive Bayes predicting Recall: {recall:.2f}\")\n",
        "print(f\"Naive Bayes predicting F1 Score: {f1_score:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBQq6x1hQGxT",
        "outputId": "aef85f11-8429-46f7-db46-ffd45e74e09c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time Logistic Regression: 49.50 seconds\n",
            "Training time Naive Bayes: 24.81 seconds\n",
            "Training time Random Forest: 100.09 seconds\n",
            "----------------\n",
            "Accuracy of model at Logistic Regression predicting: 0.9323355753318717\n",
            "Accuracy of model at Naive Bayes predicting: 0.9034652839799525\n",
            "Accuracy of model at Random Forest predicting: 0.8578590007463993\n",
            "----------------\n",
            "After resampling data\n",
            "Accuracy of model at Logistic Regression predicting: 0.9335326091378984\n",
            "Accuracy of model at Naive Bayes predicting: 0.9135132338313691\n",
            "Accuracy of model at Random Forest predicting: 0.8682705066055129\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training time Logistic Regression: {training_time_log:.2f} seconds\")\n",
        "print(f\"Training time Naive Bayes: {training_time_nb:.2f} seconds\")\n",
        "print(f\"Training time Random Forest: {training_time_rf:.2f} seconds\")\n",
        "print(\"----------------\")\n",
        "print(\"Accuracy of model at Logistic Regression predicting: {}\".format(acc_lg))\n",
        "print(\"Accuracy of model at Naive Bayes predicting: {}\".format(acc_nb))\n",
        "print(\"Accuracy of model at Random Forest predicting: {}\".format(acc_rf))\n",
        "print(\"----------------\")\n",
        "\n",
        "print(\"After resampling data\")\n",
        "print(\"Accuracy of model at Logistic Regression predicting: {}\".format(acc_lg1))\n",
        "print(\"Accuracy of model at Naive Bayes predicting: {}\".format(acc_nb1))\n",
        "print(\"Accuracy of model at Random Forest predicting: {}\".format(acc_rf1))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}